<html><head>
  <title>Tao Hu</title>
  <link rel="stylesheet" href="hint.min.css" />
  <style type="text/css">
  body {
    margin-top: 30px;
    margin-bottom: 30px;
    margin-left: 100px;
    margin-right: 100px;
  }
  p {
    margin-top: 0px;
    margin-bottom: 0px;
  }
  
  .caption {
    font-size: 34px;
    font-weight: normal;
    color: #000;
    font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
  }
  .caption-1 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
  }
  .caption-2 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #990000;
  }
  .caption-3 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #F00;
  }
  
  .caption-4 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #990000;
  }
  .content {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    text-align: justify;
  }

  .conference_name {
    font-size: 16px;
    font-weight: bold;
    color: #990000;
    font-family: Tahoma, Geneva, sans-serif;
    text-align: justify;
  }



  .content strong a {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #990000;
  }

  .pkured {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #990000;
  }
  .title-small {
    font-size: 20px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #F90;
  }
  .title-large {
    font-size: 28px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #000;
  }
  .margin {
    font-size: 10px;
    line-height: 10px;
  }
  .paper_intro{
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #934545;
  }
  .margin-small {
    font-size: 5px;
    line-height: 25px;
  }
  .margin-large {
    font-size: 16px;
    line-height: 16px;
  }
  a:link {
    text-decoration: none;
  }
  a:visited {
    text-decoration: none;
  }
  content a:link {
    text-decoration: none;
  }
  content a:visited {
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  a:active {
    text-decoration: underline;
    color: #000000;
    font-family: Tahoma, Geneva, sans-serif;
  }
  strong a:active {
    text-decoration: underline;
    color: #000000;
  }
  img
  {
   border-color: black;
  }
  
  
  </style>



<link rel="stylesheet" href="fontawesome-free-6.4.0-web/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <meta http-equiv="Content-Type" content="text/html; charset=gbk"></head>
  
  <script type="text/javascript">
    function toggle_visibility(block_id) {
        var e = document.getElementById(block_id);
        if(e.style.display == 'block')
           e.style.display = 'none';
        else
           e.style.display = 'block';
    }
 </script>	



  <body>
  
  <table border="0" width="100%">
    <tbody>
  
      <tr>
  
      <td width="337"><table>
        <tr><td>
        <a href="imgs/teng.jpg"><img src="imgs/teng.jpg"  height="370" alt="Tao Hu's portrait" border=1></td></tr>
        </table></td>
      <td width="15"></td>
      <td></td>
      <td><table border="0" width="100%">
        <tbody><tr height="20">
          <td colspan="2"></td></tr>
     <tr height="60">
          <td>
             <p class="caption">Tao Hu<br><br></p>
              <p class="content"> Final-year PhD, VISLab, University of Amsterdam, supervised by  <a href="https://www.ceessnoek.info/" target="_blank", style="font-weight: bold; color: #000;">Cees Snoek</a> and <a href="https://staff.fnwi.uva.nl/p.s.m.mettes/index.html" target="_blank", style="font-weight: bold; color: #000;">Pascal Mettes</a></p>
              <p class="content">C3.249, Science Park 904, Amsterdam</p>
              <p class="content"><strong>Email</strong>: taohu620 at gmail dot com</p>
          </td>
        </tr>
  
  
        <tr height="40">
          <td>
            <p class="margin">&nbsp;</p>
            <p class="content">

  
                <strong><a href="https://scholar.google.com/citations?hl=en&amp;user=EchdyZEAAAAJ" target="_blank">Publication</a></strong>
                  | <strong><a href="https://github.com/dongzhuoyao" target="_blank">GitHub</a>  </strong>
                  | <strong><a href="https://drive.google.com/file/d/1fIzSq-eKtsgihB66yWQySWhiUIoAvv8q/view?usp=share_link" target="_blank">CV(updated in Apr.2023)</a>  </strong>
                  |<strong>  <br> <a href="https://www.linkedin.com/in/taohu620/" target="_blank">LinkedIn</a>  </strong>
                  |<strong>  <a href="https://taohu.notion.site/Research-Note-b95da0911249407488ccf9e3f6730085" target="_blank">Research Note</a>  </strong>  
                  |<strong> <a href="https://cal.com/hu-tao-leakvj/30min" target="_blank">Chat with me</a>  </strong>
                  |<strong><a href="https://drive.google.com/file/d/1C_oQTSqua-_0001MtwJHyFfMKb-TKl8k/view?usp=sharing" target="_blank">Wechat</a>  </strong>
                  |<strong><a href="https://www.zhihu.com/people/14-54-34-43" target="_blank">Zhihu</a>  </strong>
                
  
              <!--
              <strong><a href="https://scholar.google.com/citations?hl=en&user=EchdyZEAAAAJ" target="_blank"><i class="ai ai-google-scholar" aria-hidden="true" style="font-size: 2.5em"></i></a></strong>
          <strong><a href="https://github.com/dongzhuoyao" target="_blank"> <i class="fa-brands fa-github" style="font-size: 2.5em"></i></a>  </strong>
          <strong><a href="https://drive.google.com/file/d/1fIzSq-eKtsgihB66yWQySWhiUIoAvv8q/view?usp=share_link" target="_blank"><i class="ai ai-cv" style="font-size: 2.5em"></i></a>  </strong>
          <strong><a href="https://www.linkedin.com/in/taohu620/" target="_blank"><i class="fa-brands fa-linkedin-in" style="font-size: 2.0em"></i></a>  </strong>
          <br>
          <strong> <a href="https://cal.com/hu-tao-leakvj/30min" target="_blank"><i class="fa-solid fa-calendar" style="font-size: 2.5em"></i></a>  </strong>
          <strong><a href="https://drive.google.com/file/d/1C_oQTSqua-_0001MtwJHyFfMKb-TKl8k/view?usp=sharing" target="_blank"><i class="fa-brands fa-weixin" style="font-size: 2.5em"></i></a>  </strong>
          <strong><a href="https://www.zhihu.com/people/14-54-34-43" target="_blank"><i class="fa-brands fa-zhihu" style="font-size: 2.5em"></i></a>  </strong>
          <br>
          <strong><a href="https://taohu.notion.site/Research-Note-b95da0911249407488ccf9e3f6730085" target="_blank">Research Note</a>  </strong>  
         
              -->

        </p>
          </td>
        </tr>

       

        <tr height="20">
          <td colspan="2"></td></tr>
      </tbody></table></td>
    </tr>
  </tbody></table>
  <p class="margin">&nbsp;</p>

  

  
  <table border="0" >
    <tbody>
      <tr>
        <td width="900"> 
          <strong><p align="justify" class="content">
          Focused on introducing inductive bias into neural network to achieve data-efficiency by few-shot learning, generative model, etc.
          Have a conviction that generative modelling will be the future of discriminative modelling.
        </p></strong>
        
          <p align="justify" class="content" style="color:#dc1017">
            <strong>I'm on the job market. Feel free to contact me. [AIGC expert]</strong>
            </p
    <br>
      </tr>
     
    </tbody>
  </table>


  <table border="0" >
    <tbody>
      <tr>
        <img src="imgs/wechat2.jpg"  height="320" alt="Tao Hu's wechat" border=-0>
      </tr>
    </tbody>
  </table>

  
  <br>
  <br>


  

<!--


  <p style="font-size: small;color:cornflowerblue;font-weight: 500;font-family: Tahoma, Geneva, sans-serif;">
    -----BEGIN PGP PUBLIC KEY BLOCK-----
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=CfwG
-----END PGP PUBLIC KEY BLOCK-----
  </p>

  -->




  <strong><p class="pkured">News:</p></strong> 

  <br>
  <!--
  <p  align="justify" class="content"><strong>[Sep. 2022] I am open to industry opportunity now.</p></strong>
  -->
  <p align="justify" class="content"><strong>[May. 2023] A paper about the flow matching is submitted, thanks to my coorporators~</p></strong>
  <p  align="justify" class="content"><strong>[Apr. 2023] Co-supervise new master students: Junjie Xu(Umich), Zeqiu Yu(Northwestern Uni) with Meng Tang from UCMerced, welcome on board!</p>
  <p  align="justify" class="content"><strong>[Apr. 2023] I am selected for CVPR 2023 Doctoral Consortium. Here is the <a target="_blank" href="pdf/research_statement_taohu_cvpr_doctor_consortium.pdf"> Summary of my PhD Research. </a></p></strong>
  <p  align="justify" class="content"><strong>[March. 2023] One CVPR 2023 and New Blog: <a target="_blank" href="https://taohu.notion.site/Flow-Matching-Make-CNF-great-again-or-diffusion-model-30c493d135e3480ab9b776c6fbb3a9cc">Flow Matching: Make CNF great again or  diffusion model++?</a> </p></strong>
  <p  align="justify" class="content"><strong>[Jan. 2023] Committee members confirmed: Theo Gevers, Marcel Worring, Efstratios Gavves, Bernard Ghanem, Tim Salimans </p></strong>
  <p  align="justify" class="content"><strong>[Oct. 2022] "Self-Guided Diffusion Models" was accepted by two NeurIPS 2022 workshops.</p></strong>
  <p  align="justify" class="content"><strong>[Dec. 2021] My mentee Martine Toering's Master Thesis won </strong><strong><a target="_blank" href="https://amsterdamdatascience.nl/news/winners-of-the-ads-thesis-awards-announced/">the ADS Thesis Awards</a>.</p></strong>



  <br><br>  
  

  
  <!--
    <img src="imgs/bug.gif" > -->

  
  <p id="sect-publications" class="title-large">Publications</p>
  

  <p><a href="https://scholar.google.com/citations?hl=en&user=EchdyZEAAAAJ" target="_blank">(Full Publication)</a>, <strong>* Equal contribution</strong></p>
  

  
  <table border="0">
    <tbody><tr>
      <td width="188"><a href="s" target="_blank"><img src="imgs/fm.png" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>A paper about Flow Matching</strong></p>
        <p class="content"></p>
        <p class="conference_name"> </p>

        <p class="paper_intro" >In submission.</p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        
        <strong><a href="http://taohu.me/lfm" target="_blank">Project</a> </strong>
        |
        <strong><a href="https://github.com/dongzhuoyao/uspace" target="_blank">Code</a> </strong>
      
        

      </tbody></table>
  <div id="bibtex_tlfm" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>

      </code></pre></div></small>
      </div>
  <p class="margin-small">&nbsp;</p>


  <table border="0">
    <tbody><tr>
      <td width="188"><a href="s" target="_blank"><img src="imgs/avatar_sgdm.png" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>Self-Guided Diffusion Models</strong></p>
        <p class="content"><strong>Vincent Tao Hu*</strong>,David W Zhang*, Yuki M. Asano, Gertjan J. Burghouts, Cees G. M. Snoek</p>
        <p class="conference_name">CVPR 2023, NeurIPS 2022 SSL and SBM workshops. </p>

        <p class="paper_intro" >A bridge between the community of self-supervised learning and diffusion models.</p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        
        <strong><a href="https://arxiv.org/abs/2210.06462" target="_blank">Paper</a> </strong>
        <strong>| </strong>
        <strong><a href="http://taohu.me/sgdm" target="_blank">Project</a> </strong>
        <strong>| </strong>
        <strong><a href="" target="_blank">Code(Coming soon)</a> </strong>
        <strong>| </strong>
        <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_sgdm');">Bibtex</a></strong> <br> </p>  </tr>
       
      </tbody></table>
  <div id="bibtex_sgdm" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>
        @inproceedings{hu2022selfguided,
          title={Self-Guided Diffusion Models},
          author={Vincent Tao Hu and David W Zhang and Yuki M. Asano and Gertjan J. Burghouts and Cees G. M. Snoek},
          year={2023},
          booktitle={CVPR}
      }
      </code></pre></div></small>
      </div>
  <p class="margin-small">&nbsp;</p>


  <table border="0">
    <tbody><tr>
      <td width="188"><a href="s" target="_blank"><img src="imgs/wacv22.png" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>Self-supervised Video Representation Learning with Cross-Stream Prototypical Contrasting</strong></p>
        <p class="content">Martine Toering, Ioannis Gatopoulos, Maarten Stol, <strong>Vincent Tao Hu </strong></p>
        <p class="conference_name">WACV 2022</p>
        <p class="paper_intro" >Improve video representation by constrasting Prototypical features.</p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        
        <strong><a href="https://arxiv.org/abs/2106.10137.pdf" target="_blank">Paper</a>|<a href="https://github.com/martinetoering/ViCC" target="_blank">Code</a> </strong> |
        <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_vicc');">Bibtex</a></strong> <br> </p>  </tr>
  </tbody></table>
  <div id="bibtex_vicc" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>@inproceedings{toering2022self,
        title={Self-supervised Video Representation Learning with Cross-Stream Prototypical Contrasting},
        author={Toering, Martine and Gatopoulos, Ioannis and Stol, Maarten and Hu, Vincent Tao},
        booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
        pages={108--118},
        year={2022}
      }
      </code></pre></div></small>
      </div>
  <p class="margin-small">&nbsp;</p>
  
  <table border="0">
    <tbody><tr>
      <td width="188"><a href="s" target="_blank"><img src="imgs/pointmixup.gif" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>PointMixup: Augmentation for Point Clouds</strong></p>
        <p class="content">Yunlu Chen*, <strong>Vincent Tao Hu</strong>*,Efstratios Gavves, Thomas Mensink, Pascal Mettes, Pengwan Yang, Cees G. M. Snoek</p>
        <p class="conference_name">ECCV 2020,Spotlight</p>
        <p class="paper_intro" >A simple augmentation method based on MixUp to boost the performance on related tasks of point cloud.</p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        
        <strong><a href="https://arxiv.org/abs/2008.06374" target="_blank">Paper</a>|<a href="https://github.com/yunlu-chen/PointMixup/" target="_blank">Code</a> </strong> |
        <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_pointmixup');">Bibtex</a></strong> <br> </p>  </tr>
  </tbody></table>
  <div id="bibtex_pointmixup" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>@INPROCEEDINGS{ChenECCV20,
        author = {Yunlu Chen and Vincent Tao Hu and Efstratios Gavves and Thomas Mensink and Pascal Mettes and Pengwan Yang and Cees G. M. Snoek},
        title = {PointMixup: Augmentation for Point Clouds},
        booktitle = {European Conference on Computer Vision},
        month = {August},
        year = {2020},
        address = {Glasgow, UK},
        pdf = {},
        note = {Spotlight presentation, top 5%},
        abstract = { }
      }
      </code></pre></div></small>
      </div>
  <p class="margin-small">&nbsp;</p>


  
  <table border="0">
    <tbody><tr>
      <td width="188"><a href="" target="_blank"><img src="imgs/focal.png" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>Localizing the Common Action Among a Few Videos</strong></p>
        <p class="content">Pengwan Yang*, <strong>Vincent Tao Hu</strong>*, Pascal Mettes, Cees G. M. Snoek</p>
        <p class="conference_name">ECCV 2020</p>
        <p class="paper_intro" >Localizing the temporal extent of an action in a long untrimmed video by attention techniques. </p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        <strong><a href="https://arxiv.org/abs/2008.05826" target="_blank">Paper</a>| <a href="https://github.com/PengWan-Yang/commonLocalization" target="_blank">Code</a> </strong> |
        <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_cl');">Bibtex</a></strong> <br> </p>  </tr>
  </tbody></table>
  <div id="bibtex_cl" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>@INPROCEEDINGS{YangECCV20,
        author = {Pengwan Yang and Vincent Tao Hu and Pascal Mettes and Cees G. M. Snoek},
        title = {Localizing the Common Action Among a Few Videos},
        booktitle = {European Conference on Computer Vision},
        month = {August},
        year = {2020},
        address = {Glasgow, UK},
        pdf = {},
        abstract = { }
      }
      </code></pre></div></small>
      </div>
  <p class="margin-small">&nbsp;</p>


  <table border="0">
    <tbody><tr>
      <td width="188"><a href="http://taohu.me/SILCO/" target="_blank"><img src="imgs/avatar_silco.png" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>SILCO: Show a Few Images, Localize the Common Object</strong></p>
        <p class="content"><strong>Tao Hu</strong>, Pascal Mettes, Jia-Hong Huang, Cees G. M. Snoek</p>
        <p class="conference_name">ICCV 2019</p>
        <p class="paper_intro" >Design a graph network and apply attention on them to solve the problem of common object localization. </p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        <strong><a href="https://dongzhuoyao.github.io/SILCO/" target="_blank">Project</a></strong> |
        <strong><a href="pdf/19iccv-silco.pdf" target="_blank">Paper</a></strong> |
        <strong><a href="https://github.com/dongzhuoyao/silco_" target="_blank">Code</a></strong> |
        <strong><a href="pdf/19iccv_silco_poster.pdf" target="_blank">Poster</a></strong> |
        <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_silco');">Bibtex</a></strong> <br> </p>  </tr>
  </tbody></table>
  <div id="bibtex_silco" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>@article{silco2019,
        title={SILCO: Show a Few Images, Localize the Common Object},
        author={Tao HU and Pascal Mettes and Jia-Hong Huang and Cees  Snoek},
        booktitle=ICCV,
        year={2019}
      }
      </code></pre></div></small>
      </div>
  <p class="margin-small">&nbsp;</p>
  

  
  <table border="0">
      <tbody><tr>
        <td width="188"><a href=""><img src="imgs/avatar_amcg.png" border="1" width="288"></a></td>
        <td width="20"></td>
        <td valign="middle" width="900"><p class="content"><strong>Attention-based Multi-Context Guiding for Few-Shot Semantic Segmentation</strong></p>
          <p class="content"><strong>Tao Hu</strong>, Pengwan Yang, Chiliang Zhang, Gang Yu, Yadong Mu, Cees G.M. Snoek</p>
          <p class="conference_name">AAAI 2019,Spotlight</p>
          <p class="paper_intro" >Solve the few-shot segmentation problem by applying attention in multi-scales.</p>
          <p class="margin-small">&nbsp;</p>
         <p class="content">
          <strong><a href="pdf/few-shot-seg.pdf" target="_blank">Paper</a></strong> |
          <strong><a href="pdf/few-shot-seg-supplemental.pdf" target="_blank">Supp</a></strong> |
          <strong><a href="pdf/19aaai-fss-poster.pdf" target="_blank">Poster</a></strong> |
          <strong><a href="https://github.com/dongzhuoyao/tensorpack/tree/deeplab/examples/one-shot-seg" target="_blank">Code</a></strong> |
    
          <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_fss');">Bibtex</a></strong> <br> </p>  </tr>
    </tbody></table>
    <div id="bibtex_fss" style="display:none;">
        <small><div class="content"><pre class="highlight">
        <code>@article{tao2018fss,
          title={Attention-based Multi-Context Guiding for Few-Shot Semantic Segmentation},
          author={Tao HU and Pengwan Yang and Chiliang Zhang and Gang Yu and Yadong Mu and Cees Snoek},
          booktitle=AAAI,
          year={2019}
        }
        </code></pre></div></small>
        </div>

    <p class="margin-small">&nbsp;</p>

  <br>
  <br>

  <table border="0">
    <tbody><tr>
      <td width="188"><a href=""><img src="imgs/video_retrieval.png" border="1" width="288"></a></td>
      <td width="20"></td>
      <td valign="middle" width="900"><p class="content"><strong>Query by Activity Video in the Wild</strong></p>
        <p class="content"><strong>Tao Hu</strong>, William Thong, Pascal Mettes, Cees G.M. Snoek</p>
        <p class="conference_name">draft</p>
        <p class="paper_intro" >Few-shot video retrieval.</p>
        <p class="margin-small">&nbsp;</p>
       <p class="content">
        <strong><a href="pdf/activity_retrieval.pdf" target="_blank">Paper</a></strong> |
        <strong><a href="https://github.com/dongzhuoyao/video-query-in-the-wild" target="_blank">Code</a></strong> 
        <strong><a style="cursor: pointer; cursor: hand;" onclick="toggle_visibility('bibtex_retrieval');">Bibtex</a></strong> <br> </p>  </tr>
  </tbody></table>
  <div id="bibtex_retrieval" style="display:none;">
      <small><div class="content"><pre class="highlight">
      <code>@article{huvideoretrieval,
        title={Query by Activity Video in the Wild},
        author={Tao Hu, William Thong, Pascal Mettes, Cees G.M. Snoek},
        booktitle=WIP,
        year={2019}
      }
      </code></pre></div></small>
      </div>

  <p class="margin-small">&nbsp;</p>
  
  

  
<p  class="title-large">Academic Activities</p>


<p class="content"><strong><a href="">Reviewer for CVPR 20/21/22/23, ECCV20/22, ICLR22/23, NeurIPS22, AAAI-23 Program Committee Member, BMVC21/22/23, WACV21/22/23, ICRA, TMM, ACCV,  etc.</a></strong></p>
<p class="content"><strong><a href="https://uvadlc.github.io/">Teaching Assistant for  <a href="https://uvadlc.github.io/"  target="_blank" >deep learning course(2019/20)</a>  with    <a href="http://www.egavves.com"  target="_blank" >Efstratios Gavves </a> in University of Amsterdam.</strong></p>
<p class="content"><strong><a href="https://iplab.dmi.unict.it/icvss2019/Home">Sicily Summer School 2019, Gran Canaria summer school 2021</a></strong></p>

<br>
 


  <p id="sect-talks" class="title-large">Supervision</p>

  <p class="content"><strong><a href="">Andrea Rigo(M.S.),2022=>Depth-aware generative modeling</a></strong></p>
  <p class="content">Master Thesis(2022)</p>

  <p class="content"><strong><a href="pdf/Master_Thesis_Toering_Video_cross_stream.pdf">Martine Toering(M.S.),2021=>Self-supervised Video Representation Learningwith Cross-Stream Prototypical Contrasting</a></strong></p>
  <p class="content">Master Thesis(2021)</p>

  <p class="content"><strong><a href="">Hinrik SnÃ¦r(M.S.),2021=>Improvement in efficiency for automated quality control for fish processing using semantic segmentation</a></strong></p>
  <p class="content">Master Thesis(2020)</p>

  <p class="content"><strong><a href="pdf/Toering_11302925_Thesis.pdf">Martine Toering(B.A.),2019=>Video Classification from scratch</a></strong></p>
  <p class="content">Bachelor Thesis(2019)</p>
  
  <p class="content"><strong><a href="">Paulien Rouwendaal(M.S.),2019=>Full and point supervised learning strategies for table cell detection</a></strong></p>
  <p class="content">Master Thesis(2019)</p> 
  <br>


  <p id="sect-talks" class="title-large">Misc</p>

  <p> <img src="https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fdongzhuoyao%2Facad-homepage%2Fgoogle-scholar-stats%2Fgs_data_shieldsio.json&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations">  </p>
  <p class="content"><strong><a href="https://www.youtube.com/@vincenttalk">Youtube(For Fun): Vincent Talk</a></strong></p>
  

  <br>



<br><br><br><br>
  <p class="content">Template is borrowed from  <a href="http://people.csail.mit.edu/junyanz/">Yan-Jun Zhu</a>.</p>.

  

    <table border="0", style="opacity: 0;">
    <tbody><tr>
      <td width="280">
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=21CLf19jYJsPiUe2kjErKACvUCh1zZ2lnWcRCsPJRa4&cl=ffffff&w=a"></script>
      </td>
      </tr>
  </tbody></table>

  
  </body></html>
  